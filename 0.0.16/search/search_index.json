{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>A quick example is provided here.</p> <p>Analogy</p> <p><code>keras</code> is to <code>tensorflow</code> as <code>flicker</code> is to <code>pyspark</code></p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from pyspark.sql import SparkSession\nfrom flicker import FlickerDataFrame\n\n# (Optional) Create a spark session, if needed.\nspark = SparkSession.builder.appName('PySparkShell').getOrCreate()\n\n# Create a dummy Flicker DataFrame using normally distributed random data of shape (100, 3)\ndf = FlickerDataFrame.from_shape(spark, nrows=100, ncols=3,\n                                 columns=['a', 'b', 'c'], fill='randn')\n\n# See the nice printed dataframe in ipython/jupyter\ndf\n\n# Pandas-like API to inspect a FlickerDataFrame\nprint(df.shape)\n# (100, 3)\n\nprint(df.names)\n# ['a', 'b', 'c']\n\nprint(df.dtypes)\n# [('a', 'double'), ('b', 'double'), ('c', 'double')]\n\n# One of the main features of flicker is the following handy shortcut to view the data.\n# Calling a FlickerDataFrame object, returns the first 5 rows as a pandas DataFrame.\n# See ?df for more examples on how you can use this to quickly and interactively perform analysis.\ndf()\n#           a         b         c\n# 0 -0.488747 -0.378013  0.350972\n# 1  0.224332  0.322416 -0.943630\n# 2  0.249755 -0.738754 -0.060325\n# 3  1.108189  1.657239 -0.114664\n# 4  1.768242 -2.422804 -1.012876\n\n# Another cool feature of flicker is pandas-like assignment API. Instead of having to\n# use .withColumn(), you can simply assign. For example, if we wanted to create a new\n# column that indicates if df['a'] is positive or not, we can do it like this:\ndf['is_a_positive'] = df['a'] &gt; 0\ndf()\n#           a         b         c  is_a_positive\n# 0 -0.488747 -0.378013  0.350972          False\n# 1  0.224332  0.322416 -0.943630           True\n# 2  0.249755 -0.738754 -0.060325           True\n# 3  1.108189  1.657239 -0.114664           True\n# 4  1.768242 -2.422804 -1.012876           True\n\n# These features can intermixed in nearly every imaginable way. Here are some quick examples.\n# Example 1: show the first 5 rows of the dataframe that has only 'a' and 'c' columns selected.\ndf[['a', 'c']]()\n\n# Example 2: Filter the data to select only the rows that have a positive value in column 'a' and\n# show the first 3 rows of the filtered dataframe.\ndf[df['is_a_positive']](3)\n#           a         b         c  is_a_positive\n# 0  0.224332  0.322416 -0.943630           True\n# 1  0.249755 -0.738754 -0.060325           True\n# 2  1.108189  1.657239 -0.114664           True\n\n# Example 3: Show first 2 rows that have a positive product of 'a' and 'b'\ndf[(df['a'] * df['b']) &gt; 0][['a', 'b']](2)\n#           a         b\n# 0 -0.488747 -0.378013\n# 1  0.224332  0.322416\n</code></pre>"},{"location":"#motivation","title":"Motivation","text":"<p>PySpark DataFrame API is a copy of the Scala API.</p>"},{"location":"#whats-next","title":"What's next?","text":"<p>Try out the Tutorial or the Examples.</p>"}]}